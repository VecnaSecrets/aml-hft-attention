{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from src.preprocess import *\n",
    "from src.models import *\n",
    "from src.utils import *\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up\n",
    "DEVICE = 'cuda' if t.cuda.is_available() else 'cpu'\n",
    "DEVICE = 'mps' if t.backends.mps.is_available() else DEVICE\n",
    "DATASET_PATH = './dataset/result.csv'\n",
    "LOOK_FWD = 700\n",
    "W_SIZE = 400\n",
    "THR = 0.000001\n",
    "TRAIN_TEST_R = 0.8\n",
    "TRAIN_VAL_R = 0.8\n",
    "HIDDEN = 60\n",
    "N_LAYERS = 5\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "unzip_dataset('./dataset/')\n",
    "pckl_name = './dataset/dataset.pckl'\n",
    "if os.path.isfile(pckl_name):\n",
    "    print('loading the dataset...')\n",
    "    with open(pckl_name, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "else: \n",
    "    dataset = pd.read_csv(DATASET_PATH, index_col=0)\n",
    "    print('saving the dataset...')\n",
    "    with open(pckl_name, 'wb+') as f:\n",
    "        pickle.dump(dataset, f)\n",
    "\n",
    "dataset = dataset[:500000]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = generate_labels(dataset, LOOK_FWD, THR)[LOOK_FWD:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipe(W_SIZE)\n",
    "\n",
    "train_index = int((dataset.shape[0] - LOOK_FWD * 2 - W_SIZE) * TRAIN_TEST_R)\n",
    "test_index_start = train_index + W_SIZE\n",
    "ds_train = dataset[:train_index]\n",
    "ds_test = dataset[test_index_start: - LOOK_FWD * 2]\n",
    "\n",
    "dataset = None\n",
    "\n",
    "pipe.fit(ds_train)\n",
    "\n",
    "train_t = pipe.transform(ds_train)\n",
    "test_t = pipe.transform(ds_test)\n",
    "\n",
    "train_l_t = t.tensor(labels[:train_t.shape[0]])\n",
    "test_l_t = t.tensor(labels[test_index_start:test_index_start + test_t.shape[0]])\n",
    "\n",
    "train_val_idx = int(train_l_t.shape[0] * TRAIN_VAL_R)\n",
    "\n",
    "train_ds = t.utils.data.TensorDataset(train_t[:train_val_idx], train_l_t[:train_val_idx])\n",
    "val_ds = t.utils.data.TensorDataset(train_t[train_val_idx:], train_l_t[train_val_idx:])\n",
    "test_ds = t.utils.data.TensorDataset(test_t, test_l_t)\n",
    "\n",
    "train_dl = t.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "val_dl = t.utils.data.DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "test_dl = t.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Att_GRU(train_t.shape[2], 5, 20, W_SIZE, DEVICE).to(device=DEVICE)\n",
    "model(train_t[500:505].to(device=DEVICE)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_1 = Att_GRU(test_t.shape[2],\n",
    "                  n_layers=N_LAYERS,\n",
    "                  hidden=HIDDEN,\n",
    "                  device=DEVICE,\n",
    "                  window=W_SIZE).to(device=DEVICE)\n",
    "optimizer = t.optim.Adam(model.parameters())\n",
    "lf = t.nn.CrossEntropyLoss()\n",
    "sm = SummaryWriter('./runs')\n",
    "\n",
    "train(train_dl, val_dl, model, optimizer, lf, 10, device=DEVICE, sm=sm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
